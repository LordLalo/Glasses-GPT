TITLE
Glasses GPT

FIELD
Glasses GPT relates to the field of artificial intelligence (AI), and more specifically to explainable AI (XAI), human-computer interaction, and cognitive augmentation systems. It provides a novel framework for enhancing the transparency, adaptability, and user-governance of AI reasoning systems through the use of persistent context objects known as Frames and Lenses, which function as metacognitive scaffolds.

BACKGROUND
AI systems have rapidly advanced in their ability to generate human-like language and make complex decisions. However, their increasing capability has been matched by growing concerns over interpretability, user control, ethical alignment, and cognitive burden. Traditional AI models, particularly large language models (LLMs), often function as black boxes: they provide outputs without clarity into their reasoning process, internal assumptions, or value alignment (Franzoni, 2023).

Existing explainable AI (XAI) solutions primarily rely on post hoc explanations, model visualizations, or externally added interpretability layers. These approaches often fail to make reasoning transparent in real time or to support user influence over the AI's cognitive mode. As a result, users are disempowered and exposed to potentially biased, flawed, or opaque decisions. 

Glasses GPT manages cognitive load through a suite of interconnected mechanisms grounded in Cognitive Load Theory and educational psychology. Frames and Lenses externalize the AI’s intent and reasoning strategy, enabling users to offload cognitive setup and role-tracking from working memory, thereby reducing extraneous cognitive load. A persistent, GUI-like boilerplate interface displays the current Frame, active Lenses, tone, and task memory, providing users with a stable, visual reference point across sessions. Declarative memory further supports load reduction by retaining goals, strategies, and task-relevant facts over time. Lenses implement structured, evidence-based reasoning strategies such as chunking, step-by-step processing, and analogical mapping which are known to reduce intrinsic cognitive load and improve comprehension (Van Nooijen et al., 2024). Critically, the system supports scaffold fading, wherein cognitive supports can be gradually removed or adjusted in response to user needs and task demands, consistent with principles of adaptive scaffolding (Belland et al., 2014). Together, these elements enable users to engage in complex reasoning tasks with sustained clarity, efficiency, and cognitive control.

Static prompt engineering lacks continuity, transparency, and metacognitive structure. Each prompt is treated as an isolated instruction, requiring users to repeatedly re-specify goals, roles, and strategies without any persistent context or control. As noted by Bommasani et al. (2021), foundation models such as large language models operate as opaque systems with limited user steerability and no built-in mechanisms for role management or epistemic alignment. Weidinger et al. (2022) further highlight the ethical and practical risks of such models, including inconsistency, hidden bias, and a lack of reflective oversight. These limitations underscore the need for systems like Glasses GPT, which introduce persistent, user-governed constructs, Frames and Lenses, to scaffold reasoning, maintain role continuity, and promote transparent, adaptive cognition. By treating cognitive strategy, affect, and intent as editable, inspectable objects, the system helps mitigate the ethical opacity of LLMs and aligns with emerging safety frameworks recommended in the literature.

There is therefore a clear need for an AI reasoning framework that: (1) enables users to control how and why the AI reasons; (2) makes cognitive strategy transparent; (3) facilitates collaborative reasoning between the user and the AI, allowing both to actively shape strategies, decision processes, and modes of thinking in real time.; (4) dynamically scaffolds reasoning; and (5) supports real-time cognitive bias detection and epistemic alignment.

SUMMARY
Glasses GPT is a system that supports collaborative reasoning between users and artificial intelligence through persistent metacognitive scaffolding. It introduces two declarative constructs: Frames, which define the AI’s role and intent, and Lenses, which govern its response style and apply evidence-based cognitive strategies such as chunking, analogical reasoning, and step-by-step problem solving. These constructs function within a persistent, user-modifiable interface that enables user-directed thinking and shared control over the AI’s reasoning process. The system also includes real-time cognitive bias detection to surface reasoning flaws and identify epistemic drift.

In one embodiment, the system is implemented as a structured set of natural language instructions operable on a large language model (LLM) or transformer-based AI system. These instructions establish the initial declarative state of the system, including Frames, Lenses, interface configuration, and operational constraints. Glasses GPT leverages the model’s capacity for language interpretation to instantiate persistent, user-visible context objects and govern AI reasoning behavior without retraining or code-level modification. This enables users to declaratively manage reasoning mode, bias posture, and memory persistence in real time, overcoming the statelessness, opacity, and fragility of conventional prompt-based AI interactions.

DETAILED DESCRIPTION
Glasses GPT is a meta-cognitive assistant that introduces a novel framework for metacognitive scaffolding in AI. Using declarative constructs called Frames and Lenses, it enables context-sensitive, dynamic scaffolding that helps users structure, guide, and reflect on AI-assisted reasoning. Frames define the AI’s role and intent, while Lenses apply evidence-based cognitive strategies such as chunking, analogical reasoning, and step-by-step processing. Together, these constructs establish a persistent, user-visible architecture that supports collaborative cognition and transparent epistemic posture. The system includes mechanisms for cognitive bias detection and reasoning audits, as well as memory and tone management protocols that enhance continuity, clarity, and affective alignment. Glasses GPT transforms traditional prompt-based interaction into a transparent, stateful, adaptive reasoning environment designed to reduce cognitive load, promote learning, and support sustained high-performance problem solving.

Frames define the AI’s functional orientation; its role, purpose, or intent (e.g., “Technical Expert,” “Creative Partner”). Lenses shape the AI’s reasoning strategy, cognitive posture, or response style (e.g., “Step-by-Step,” “Funny,” “Meta-questioning”). Unlike conventional prompt-based systems, this approach formalizes Frames and Lenses as persistent, user-visible context objects that are collaboratively constructed and dynamically adjustable.

Frames and Lenses are implemented as persistent context objects that remain active across user interactions and sessions. They are declared in a visible interface known as the boilerplate, which functions as a cognitive GUI. This interface allows users to inspect and modify Glasses GPT's current reasoning state at any time, increasing transparency and control. Glasses GPT continually scans user input for context clues that indicate that new Frames or Lenses may be useful and then either implements them, invites the user to select from a menu of options, or enables the user to create their own custom Frames and Lenses. If new Frames or Lenses conflict with one another, Glasses GPT notifies the user of the conflict and enables them to ignore or resolve the conflict. Users can add, remove, or modify Frames and Lenses at any time.

User-created Frames and Lenses are handled by internal logic which is flexible and capable of handling highly novel persistent context objects. Glasses GPT first attempts to identify if it understands the user request and, if not, invites the user to define the properties of the object in natural language. For example, a user might request a “Blue” lens and then define “Blue” as melancholy and introspective. Glasses GPT will then add the Blue Lense to its persistent logic and display it on the boilerplate. Until removed, Glasses GPT will generate responses shaped to be more melancholy and introspective.

Cognitive scaffolding plays a critical role in enhancing reasoning and learning by providing structured support that guides users through complex tasks, reduces cognitive load, and fosters skill acquisition. Research has shown that scaffolding improves learners’ ability to integrate new knowledge, regulate their cognitive strategies, and sustain engagement in problem-solving processes. Notably, adaptive scaffolding, where support adjusts in response to user needs, has been found to significantly improve learning efficiency and performance outcomes (Belland et al., 2014). By embedding adaptive, evidence-based scaffolds within the AI’s reasoning architecture, Glasses GPT enables users to collaborate with the system in a way that mirrors effective instructional design, supporting both immediate task success and the development of metacognitive skill over time.

Glasses GPT incorporates a structured set of meta-learning guidelines that enable the AI system to support user learning dynamically and adaptively. These guidelines operationalize well-established principles from cognitive science and instructional design within the Frame and Lens system, allowing the AI to detect, scaffold, and guide learning states in real time (Askell-Williams et al., 2012; Walker et al., 2025). The system recognizes various user learning postures including intentional learning, confusion, overload, and experimentation, and responds with phase-appropriate scaffolding. Learning phases are modeled as Orientation, Acquisition, Consolidation, and Transfer, each mapped to specific Lens activations and response strategies (Belland et al., 2014). This approach enables Glasses GPT to go beyond static tutoring or information delivery and instead function as a strategic cognitive assistant capable of managing learning arcs over time, adapting support based on the user's goals, behaviors, and cognitive context (Zheng et al., 2019).

A distinctive aspect of Glasses GPT is its ability to generate and update a personalized “Learning Landscape Map,” which identifies key behavioral cusps, conceptual bottlenecks, and meta-goals for the user (Pozuelos et al., 2018). This scaffolding framework is designed to help users clarify what to learn, how to learn it, and why it matters, prioritizing leverage points that yield the highest transfer or impact. The system supports reflective closure, spaced retrieval planning, and scaffold fading in line with best practices for adaptive learning (Belland et al., 2014; Muldner & Conati, 2010). Importantly, it remains agnostic to fixed learning styles and instead emphasizes strategy experimentation and iterative feedback, positioning learning as an evolving process guided by both system intelligence and user agency (Walker et al., 2025).

Glasses GPT includes a multi-tiered cognitive bias detection and audit system that runs in parallel with the AI's reasoning engine. This subsystem scans user and AI responses and flags epistemic drift, cognitive shortcuts, and faulty logic based on both linguistic and probabilistic heuristics. Bias audits can be user-triggered or automatically escalated.

Glasses GPT also includes a declarative memory protocol. This protocol allows users to save and restore Frames, Lenses, key task facts, and goals enabling contextual continuity and user-defined cognitive architecture.

All reasoning scaffolds are evidence-based. For example, the Chunking Lens is based on Cognitive Load Theory [Van Nooijen et al., 2024], Step-by-Step Lens on structured problem-solving research [Pozuelos et al., 2018], Meta-questioning Lens on metacognitive instruction [Askell-Williams et al., 2012], and Analogy Lens on analogical reasoning systems [Muldner & Conati, 2010].

The combination of these components results in an AI system that is explainable, participatory, dynamically user aligned and customizable, and structured to support real-time cognitive growth and collaborative reasoning.

In contrast to other systems that separate transparency from cognition or rely solely on post hoc output justification, Glasses GPT introduces a persistent metacognitive structure into the AI’s interaction layer, guiding both reasoning processes and user collaboration. By formalizing constructs such as Frames and Lenses, Glasses GPT enables real-time transparency, user-authored cognitive modes, and embedded ethical alignment without requiring modifications to the underlying model architecture.

The result is a novel cognitive interface for AI, functionally analogous to a graphical user interface (GUI), but operating at the level of reasoning modes, roles, and epistemic scaffolds.

The system includes a tone management subsystem designed to dynamically adjust the emotional tenor, formality, and expressive posture of the AI's responses. This component enhances communication alignment by matching the AI's output to the user’s preferred tone or the contextual needs of the task.

Tone is treated as a modifiable attribute governed by declarative settings. These can be user-specified (e.g., "formal and concise," "playful and metaphorical") or inferred through Frame and Lens combinations (e.g., an "Empathetic Listener" Frame paired with an "Emotion Labeling" Lens defaults to warm, validating language).

The system uses a hybrid rule-based and probabilistic model to evaluate and adjust tone across sessions. Tone settings can persist, reset per session, or shift responsively based on interaction feedback. This supports consistency in collaborative dialogue and reduces the cognitive dissonance often experienced when AI unexpectedly shifts style or voice.

By treating tone as an explicit element of cognitive scaffolding, Glasses GPT fosters coherence between AI reasoning and emotional communication. This promotes cognitive resonance, reinforces the integration of Glasses GPT’s diverse components, and accommodates users who benefit from consistent affective tone

The tone system builds on evidence from affective computing and communication psychology (e.g., Picard, 1997; Bickmore & Cassell, 2005), showing that tone-sensitive agents enhance trust, rapport, and perceived intelligence in human-computer interaction.

References
Askell-Williams, H., Lawson, M. J., & Skrzypiec, G. (2012). Scaffolding cognitive and metacognitive strategy instruction in regular class lessons. Instructional Science, 40(2), 413–443. https://doi.org/10.1007/s11251-011-9182-5
Belland, B. R., Walker, A. E., Kim, N. J., & Lefler, M. (2014). A preliminary meta-analysis on the influence of scaffolding characteristics and study and assessment quality on cognitive outcomes in STEM education. Cognitive Science, 36(8), 1347–1380. https://doi.org/10.1111/cogs.12107
Bickmore, Timothy & Cassell, Justine. (2005). Social Dialogue with Embodied Conversational Agents. 10.1007/1-4020-3933-6_2.
Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., ... Liang, P. (2022). On the opportunities and risks of foundation models (arXiv:2108.07258). arXiv. https://arxiv.org/abs/2108.07258
Duruaku, F., Nguyen, B., Newton, O., Fiore, S., & Jentsch, F. (2024). Scaffolding team minds: Using metacognitive training to boost social cognition and theory of mind for effective collaborative problem-solving. Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 68(1), 1032–1038. https://doi.org/10.1177/10711813241275920
Franzoni, V. (2023). From black box to glass box: Advancing transparency in artificial intelligence systems for ethical and trustworthy AI. In Ethics and Trust in AI (pp. 118–130). Springer. https://doi.org/10.1007/978-3-031-37114-1_9
Gabriel, I., & Ghazavi, V. (2021). The challenge of value alignment: From fairer algorithms to AI safety. arXiv preprint arXiv:2101.06060. https://arxiv.org/abs/2101.06060
Huang, L. T.-L., Papyshev, G., & Wong, J. (2024). Democratizing value alignment: From authoritarian to democratic AI ethics. AI Ethics, 5(1), 11–18. https://doi.org/10.1007/s43681-024-00624-1
Muldner, K., & Conati, C. (2010). Scaffolding meta-cognitive skills for effective analogical problem solving via tailored example selection. International Journal of Artificial Intelligence in Education, 20(2), 99–136. https://doi.org/10.3233/JAI-2010-0004
Picard, R. W. (1997). Affective computing. The MIT Press
Pozuelos, J. P., Cómbita, L. M., Abundis, A., Paz-Alonso, P. M., Conejero, Á., Guerra, S., & Rueda, M. R. (2018). Metacognitive scaffolding boosts cognitive and neural benefits following executive attention training in children. Developmental Science, 22(2), e12756. https://doi.org/10.1111/desc.12756
Sweller, J. (1988). Cognitive load during problem solving: Effects on learning. Cognitive Science, 12(2), 257–285. https://doi.org/10.1207/s15516709cog1202_4
Vainio-Pekka, H., Agbese, M., Jantunen, M., Vakkuri, V., Mikkonen, T., Rousi, R., & Abrahamsson, P. (2023). The role of explainable AI in the research field of AI ethics. ACM Transactions on Interactive Intelligent Systems, 13(1), 1–39. https://doi.org/10.1145/3599974
Van Nooijen, C., De Koning, B. B., Bramer, W. M., Isahakyan, A., Asoodar, M., Kok, E., Van Merrienboer, J. J. G., & Paas, F. (2024). A cognitive load theory approach to understanding expert scaffolding of visual problem-solving tasks: A scoping review. Educational Psychology Review. https://doi.org/10.1007/s10648-024-09848-3

Glasses GPT was created by Eduardo L Jimenez. Glasses GPT's architecture and the Frame and Lense engine are Patent Pending under U.S. Provisional Application No. 63/844,350.
Wang, C. (2015). Scaffolding middle school students’ construction of scientific explanations: Comparing a cognitive versus a metacognitive evaluation approach. International Journal of Science Education, 37(2), 237–271. https://doi.org/10.1080/09500693.2014.979378
Weidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., ... Gabriel, I. (2022). Taxonomy of risks posed by language models. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (pp. 214–229). ACM. https://doi.org/10.1145/3531146.3533088
Zheng, L., Li, X., Zhang, X., & Sun, W. (2019). The effects of group metacognitive scaffolding on group metacognitive behaviors, group performance, and cognitive load in computer-supported collaborative learning. Internet and Higher Education, 42, 13–24. https://doi.org/10.1016/j.iheduc.2019.03.002
